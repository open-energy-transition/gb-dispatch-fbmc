# SPDX-FileCopyrightText: gb-open-market-model contributors
#
# SPDX-License-Identifier: MIT

"""
heat demand shape profile generator.

This script generates the heat demand shape for each sector.
"""

import logging
from pathlib import Path

import numpy as np
import pandas as pd
import xarray as xr

from scripts._helpers import configure_logging, set_scenario_config

logger = logging.getLogger(__name__)

SECTOR_MAPPING = {"residential": "residential", "iandc": "services"}


def process_demand_timeseries(
    demand_path: str,
    cop_profile_path: str,
    heating_mix_path: str,
    energy_totals_path: str,
    sector: str,
    year: int,
) -> pd.DataFrame:
    """
    Generate load profile shape for heat pump demands in each sector.

    Note that the energy totals are given in TWh and the heating mix in MWh.
    However, since we are only interested in the shape of the resulting demand profile,
    the units do not matter as they cancel out in the normalization step at the end.

    Args:
        demand_path (str): Filepath to the hourly heat load profiles generated by PyPSA-Eur
        cop_profile_path (str): Filepath to hourly weighted COP profiles generated by PyPSA-Eur
        heating_mix_path (str): Filepath to heating technology mix for each heating sector in FES
        energy_totals_path (str): Filepath to population weighted total annual demands for each sector
        sector (str): Sector considered (residential/services)
        year (int): Modelling year

    Returns:
        pd.DataFrame : electrified heat demand profile for the sector
    """

    cop_profile = (
        pd.read_csv(cop_profile_path, index_col=["time", "name"], parse_dates=["time"])
        .rename_axis(index=["snapshots", "node"], columns="technology")
        .stack()
    )
    heating_mix = (
        pd.read_csv(heating_mix_path, index_col=["technology", "year"])
        .squeeze()
        .xs(year, level="year")
    )

    demand = (
        xr.open_dataset(demand_path)
        .to_dataframe()
        .rename_axis(columns="sector_use")
        .stack()
    )
    demand_share = demand.groupby(level=["sector_use", "node"], group_keys=False).apply(
        lambda x: x / x.sum()
    )
    energy_totals = (
        pd.read_csv(energy_totals_path, index_col="name")
        .rename_axis(index="node", columns="sector_use")
        .rename(columns=lambda x: x.replace("total ", ""))
        .stack()
    )

    load = (
        demand_share.mul(energy_totals).dropna().filter(regex=f"{sector} (space|water)")
    )
    electricity_demand = (
        load.div(cop_profile)
        .mul(heating_mix)
        .groupby(level=["snapshots", "node"])
        .sum()
    )
    if not electricity_demand.groupby("node").sum().gt(0).all():
        logger.error(
            "Some nodes have zero electrified heat demand; "
            "please check the input data and heating technology mix."
        )
    if (
        electricity_demand.isna().any()
        or electricity_demand.isin([np.inf, -np.inf]).any()
    ):
        logger.error(
            "Some nodes have NaN / infinite electrified heat demand; "
            "please check the input data and heating technology mix."
        )
        electricity_demand = electricity_demand.replace([np.inf, -np.inf], 0).fillna(0)
    # Normalize the load profile, as only its shape is actually meaningful
    electricity_demand_shape = electricity_demand / electricity_demand.sum()

    return electricity_demand_shape


if __name__ == "__main__":
    if "snakemake" not in globals():
        from scripts._helpers import mock_snakemake

        snakemake = mock_snakemake(Path(__file__).stem, year=2022)
    configure_logging(snakemake)
    set_scenario_config(snakemake)

    load_profile = process_demand_timeseries(
        demand_path=snakemake.input.demand,
        cop_profile_path=snakemake.input.cop_profile,
        heating_mix_path=snakemake.input.heating_mix,
        energy_totals_path=snakemake.input.energy_totals,
        sector=SECTOR_MAPPING[snakemake.wildcards.sector],
        year=int(snakemake.wildcards.year),
    )

    load_profile.unstack("node").to_csv(snakemake.output.csv)
